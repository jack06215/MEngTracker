#include <opencv2/opencv.hpp>
#include <iostream>
#include <fstream>
#include <iterator>
#include <string>
#include <vector>


#include "myutils.h"
#include "frontal_warping.h"
#include "fps_stats.hpp"
#include "barter.hpp"
#include "akaze_tracker.h"
#include "kalman.h"

// FPS meter
fps_stats fps{ "main_detection" };

// Fronto-parallel generator
mat_pair normalView_pair;
mat_pair frontalView_pair;
cvMat_pair toFrontal_H;
frontal_warping frontal_gen;



// Initial homography generated by DICTA2016
cv::Mat H_10 = (cv::Mat_<double>(3, 3) <<
	0.967532250365956, -0.0494740174010926, -434.766191318088,
	-0.0647546595745570, 0.899401488837144, -434.134430452806,
	0.000441909031457467, 0.000785585161861076, 0.537044944409452);
cv::Mat tH_10 = (cv::Mat_<double>(3, 3) <<
	1.52662590547943, 0.336908659039370, 0.000822852977311612,
	0.675603129684760, 1.76757322813276, 0.00146279221141338,
	-9.19961303214176e-15, -4.51235528089903e-14, 1);
cv::Mat iMat = (cv::Mat_<double>(3, 3) <<
	1, 0, 0,
	0, 1, 0,
	0, 0, 1);

// AKAZE tracker
akaze_tracker tracker;
void cameraPoseFromHomography(const cv::MatExpr& H, cv::Mat& pose);
void writeDoubleVector(const std::string filename, const std::vector<double>& vector);
bool isNiceHomography(const cv::Mat_<double>& H);
void overlayImage(cv::Mat* src, cv::Mat* overlay, const cv::Point location = cv::Point(0, 0), double opacity = 0.0f);


int main(int argc, char *argv[])
{
	std::string filename = cv_makeFilename(".\\sampleA\\result_", 1, PNG);
	std::string output("file.txt");
	cv::Mat image_model = cv::imread(filename);
	cv::Mat quad_img = cv::imread("bandicam 2017-04-12 15-44-38-639.jpg", -1);
	if (image_model.empty() | quad_img.empty())
	{
		std::cerr << "Cannot open image frame, exiting the progam" << std::endl;
		return 2;
	}
	cv::Mat K = (cv::Mat_<double>(3, 3) <<
		image_model.cols, 0, image_model.cols/2,
		0, image_model.cols, image_model.rows/2,
		0, 0, 1);
	// model image bounding box
	std::vector<cv::Point2f> frame_corner = getBoundingBox(image_model.size());
	std::vector<cv::Point2f> quad_scaled_bb = getBoundingBox(quad_img.size());

	// bounding box: tl, tr, br, bl
	cv::Mat tmp_img_model;
	H_10.copyTo(toFrontal_H.first);
	homography_warp2(image_model, toFrontal_H.first, tmp_img_model);
	//homography_warp2(image_model, iMat, tmp_img_model);
	cv::Rect2d uBox = selectROI(filename, tmp_img_model);
	
	vector<cv::Point2f> bb = getBoundingBox(uBox);

	
	// 1. Process image model
	tracker.setFirstFrame(tmp_img_model, bb);
	// Kalman filter
	Kalman filter(bb);

	// 2. Process image frame
	int max_frames = 709;
	std::vector<double> alpha, beta, gamma;
	image_model.copyTo(normalView_pair.img_pair.first);

	for (int i = 2; i < max_frames; i++, fps.tick())
	{
		std::string filename = cv_makeFilename(".\\sampleA\\result_", i, PNG);
		std::string filename2 = cv_makeFilename(".\\sampleA\\output_", i, JPEG);
		std::string output = ".\\saveMat\\mat_" + paddingZeros(i, 4) + ".csv";
		frontal_gen.akaze2_frontal_warping(normalView_pair.img_pair, frontalView_pair.img_pair,		/* camera frames */
											normalView_pair.kp_pair, normalView_pair.desc_pair,		/* keypoint and descriptor */
											toFrontal_H.first);										/* fronto-parallel tform */
		saveMatToCsv(toFrontal_H.first, output);

		if (!frontalView_pair.img_pair.second.empty())
		{
			// Get image corners of the warped image
			cv::Mat pts_H = create_homography_map(normalView_pair.img_pair.first, toFrontal_H.first);
			cv::Mat pts_Hinv = pts_H.inv();
			std::vector<cv::Point2f> bb = transform_via_homography(frame_corner, pts_H);
			
			// 2a Perform tracking-by-detection
			tracker_result result = tracker.process(frontalView_pair.img_pair.first, bb, tracker_options::ROBUST);
			//tracker_result result = tracker.process(normalView_pair.img_pair.first, bb, tracker_options::ROBUST);
			//std::cout << result.boundingBox << '\n';
			
			// 2b Draw matches result
			if (result.inlier_matches.size())
			{
				// Draw matching result, back-project bounding box
				cv::Mat matchingMat, bbMat, matchingMat2, rotVector, pose;
				normalView_pair.img_pair.first.copyTo(bbMat);

				cv::drawMatches(tmp_img_model, result.inliers1, frontalView_pair.img_pair.first, result.inliers2, result.inlier_matches, matchingMat, cv::Scalar(255, 0, 0), cv::Scalar(255, 0, 0));
				//cv::drawMatches(tmp_img_model, result.inliers1, normalView_pair.img_pair.first, result.inliers2, result.inlier_matches, matchingMat, cv::Scalar(255, 0, 0), cv::Scalar(255, 0, 0));
				cv::Rodrigues(result.homography, rotVector);
				//double norm = cv::norm(rotVector, cv::NormTypes::NORM_L2);
				//cv::divide(norm, rotVector, rotVector);
				//alpha.push_back(rotVector.at<double>(0));
				//beta.push_back(rotVector.at<double>(1));
				//gamma.push_back(rotVector.at<double>(2));
				//std::vector<cv::Mat> rot, trans, normals;
				//cv::decomposeHomographyMat(H_10, K, rot, trans, normals);
				
				
				//// Axis-angle to rotation matrix
				//cv::Mat r;
				//cv::Mat_<double> angle(3, 1);
				//angle(0, 0) = 1.2; angle(1, 0) = 0.9; angle(2, 0) = 0.7;
				//cv::Rodrigues(angle, r);
				//std::cout << r << '\n';

				
				//std::vector<cv::Point2f> tmp_boundingBox = transform_via_homography(result.boundingBox, pts_Hinv);
				//

				//cv::Mat warped_quad_img;
				//// TODO Check for valid bounding box
				//cv::Mat T;// = getPerspectiveTransform(quad_scaled_bb, tmp_boundingBox);
				//std::vector<cv::Point2f> bbox;
				//if (isNiceHomography(getPerspectiveTransform(quad_scaled_bb, tmp_boundingBox)))
				//{
				//	bbox = filter.correct(tmp_boundingBox);
				//	T = getPerspectiveTransform(quad_scaled_bb, bbox);
				//	cv::warpPerspective(quad_img, warped_quad_img, T, bbMat.size());
				//	overlayImage(&bbMat, &warped_quad_img);
				//	drawBoundingBox(bbMat, bbox, cv::Scalar(0, 255, 0));
				//	//drawBoundingBox(bbMat, tmp_boundingBox);
				//	cv::imshow("AR result", bbMat);
				//	cv::imshow("warped object", warped_quad_img);
				//}
				//else
				//{
				//	bbox = filter.predict();
				//	T = getPerspectiveTransform(quad_scaled_bb, bbox);
				//	cv::warpPerspective(quad_img, warped_quad_img, T, bbMat.size());
				//	overlayImage(&bbMat, &warped_quad_img);
				//	drawBoundingBox(bbMat, bbox, cv::Scalar(0, 255, 0));
				//	//drawBoundingBox(bbMat, tmp_boundingBox);
				//	cv::imshow("AR result", bbMat);
				//	cv::imshow("warped object", warped_quad_img);
				//	std::cout << "Bad homography found, skip overlaying" << '\n';
				//}


				
				// Show results
				cv::imshow("fronto-tracking", matchingMat);
				//cv::imwrite(filename2, matchingMat);
				
				// Memory release
				matchingMat.release();
				bbMat.release();
			}
			else
			{
				//alpha.push_back(double(50.0f));
				//beta.push_back(double(50.0f));
				//gamma.push_back(double(50.0f));
				std::cout << "no fronto-parallel view is generated" << '\n';
			}
		}
		//std::cout << alpha.size() << '\n';
		// Memory release
		normalView_pair.swap();
		frontalView_pair.swap();
		toFrontal_H.first.copyTo(toFrontal_H.second);
		normalView_pair.img_pair.first = cv::imread(filename);
		if (normalView_pair.img_pair.first.empty())
		{
			std::cerr << "Cannot open image frame, exiting the progam" << std::endl;
			//writeDoubleVector("alpha.txt", alpha);
			//writeDoubleVector("beta.txt", beta);
			//writeDoubleVector("gamma.txt", gamma);
			return 2;
		}

		// ESC to exit the program
		if (cv::waitKey(50) == 27)
			break;
	}
	//std::vector<std::string> doubleStr;
	//std::transform(std::begin(alpha),
	//	std::end(alpha),
	//	std::back_inserter(doubleStr),
	//	[](double d) { return std::to_string(d); }
	//);
	//std::ofstream output_file("alpha.txt");
	//std::ostream_iterator<double> output_iterator(output_file, "\n");
	//std::copy(alpha.begin(), alpha.end(), output_iterator);
	//myfile.close();
	return 0;
}

void cameraPoseFromHomography(const cv::MatExpr& H, cv::Mat& pose)
{
	pose = cv::Mat::eye(3, 4, CV_32FC1);      // 3x4 matrix, the camera pose
	float norm1 = (float)norm(H.col(0));
	float norm2 = (float)norm(H.col(1));
	float tnorm = (norm1 + norm2) / 2.0f; // Normalization value

	cv::Mat p1 = H.col(0);       // Pointer to first column of H
	cv::Mat p2 = pose.col(0);    // Pointer to first column of pose (empty)

	cv::normalize(p1, p2);   // Normalize the rotation, and copies the column to pose

	p1 = H.col(1);           // Pointer to second column of H
	p2 = pose.col(1);        // Pointer to second column of pose (empty)

	cv::normalize(p1, p2);   // Normalize the rotation and copies the column to pose

	p1 = pose.col(0);
	p2 = pose.col(1);

	cv::Mat p3 = p1.cross(p2);   // Computes the cross-product of p1 and p2
	cv::Mat c2 = pose.col(2);    // Pointer to third column of pose
	p3.copyTo(c2);       // Third column is the crossproduct of columns one and two

	pose.col(3) = H.col(2) / tnorm;  //vector t [R|t] is the last column of pose
}

void writeDoubleVector(const std::string filename, const std::vector<double>& vector)
{
	std::ofstream output_file(filename);
	std::ostream_iterator<double> output_iterator(output_file, "\n");
	std::copy(vector.begin(), vector.end(), output_iterator);
	output_file.close();
}

bool isNiceHomography(const cv::Mat_<double>& H)
{
	/*	elements of a homography
		[00] [01] [02]
		[10] [11] [12]
		[20] [21] [22]
	*/
	const double det = H(0, 0) * H(1, 1) - H(1, 0) * H(0, 1);
	if (det < 0)
		return false;

	const double N1 = sqrt(H(0, 0) * H(0, 0) + H(1, 0) * H(1, 0));
	if (N1 > 0.5 || N1 < 0.1)
		return false;
	
	const double N2 = sqrt(H(0, 1) * H(0, 1) + H(1, 1) * H(1, 1));
	if (N2 > 0.5 || N2 < 0.1)
		return false;
	
	const double N3 = sqrt(H(2, 0) * H(2, 0) + H(2, 1) * H(2, 1));
	if (N3 > 0.002)
		return false;

	const double N4 = H(2, 2);
	if (N4 < 0.00043)
		return false;
	
	cv::Mat N5;
	cv::SVD::compute(H, N5, cv::noArray(), cv::noArray());
	if (N5.at<double>(0, 0) >= 400)
		return false;

	return true;
}

void overlayImage(cv::Mat* src, cv::Mat* overlay, const cv::Point location, double opacity)
{
	bool set_opacity = false;
	if (opacity <= 0.0f | opacity > 1.0f)
		set_opacity = true;

	for (int y = max(location.y, 0); y < src->rows; ++y)
	{
		int fY = y - location.y;

		if (fY >= overlay->rows)
			break;

		for (int x = max(location.x, 0); x < src->cols; ++x)
		{
			int fX = x - location.x;

			if (fX >= overlay->cols)
				break;

			if (set_opacity)
				opacity = ((double)overlay->data[fY * overlay->step + fX * overlay->channels() + 3]) / 255;

			for (int c = 0; opacity > 0 && c < src->channels(); ++c)
			{
				unsigned char overlayPx = overlay->data[fY * overlay->step + fX * overlay->channels() + c];
				unsigned char srcPx = src->data[y * src->step + x * src->channels() + c];
				src->data[y * src->step + src->channels() * x + c] = srcPx *(1. - opacity) + overlayPx * opacity;
			}
		}
	}
}