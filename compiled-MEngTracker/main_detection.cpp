#include <opencv2/opencv.hpp>
#include <iostream>

#include "myutils.h"
#include "frontal_warping.h"
#include "fps_stats.hpp"
#include "barter.hpp"
#include "akaze_tracker.h"
#include "kalman.h"

// FPS meter
fps_stats fps{ "main_detection" };

// Fronto-parallel generator
mat_pair normalView_pair;
mat_pair frontalView_pair;
cvMat_pair toFrontal_H;
frontal_warping frontal_gen;

// Kalman filter
Kalman filter(4);

// Initial homography generated by DICTA2016
cv::Mat H_10 = (cv::Mat_<double>(3, 3) <<
	0.967532250365956, -0.0494740174010926, -434.766191318088,
	-0.0647546595745570, 0.899401488837144, -434.134430452806,
	0.000441909031457467, 0.000785585161861076, 0.537044944409452);
cv::Mat tH_10 = (cv::Mat_<double>(3, 3) <<
	1.52662590547943,	0.336908659039370,	0.000822852977311612,
	0.675603129684760,	1.76757322813276,	0.00146279221141338,
	- 9.19961303214176e-15, - 4.51235528089903e-14,	1);

// AKAZE tracker
akaze_tracker tracker;
cv::Mat image_model;
std::vector<cv::Point2f> frame_corner;

void overlayImage(cv::Mat* src, cv::Mat* overlay, const cv::Point location = cv::Point(0, 0), double opacity = 0.0f);


int main(int argc, char *argv[])
{
	std::string filename = cv_makeFilename(".\\sampleA\\result_", 1, PNG);
	image_model = cv::imread(filename);
	cv::Mat quad_img = cv::imread("MEngShowcase.png", -1);
	if (image_model.empty() | quad_img.empty())
	{
		std::cerr << "Cannot open image frame, exiting the progam" << std::endl;
		return 2;
	}
	
	// model image corners
	frame_corner.push_back(cv::Point2f(1, 1));									// tl
	frame_corner.push_back(cv::Point2f(image_model.cols, 1));					// tr
	frame_corner.push_back(cv::Point2f(image_model.cols, image_model.rows));	// br
	frame_corner.push_back(cv::Point2f(1, image_model.rows));					// bl

	// bounding box: tl, tr, br, bl
	cv::Mat tmp_img_model;
	H_10.copyTo(toFrontal_H.first);
	homography_warp2(image_model, toFrontal_H.first, tmp_img_model);
	cv::Rect2d uBox = selectROI(filename, tmp_img_model);
	
	vector<cv::Point2f> bb;
	bb.push_back(cv::Point2f(static_cast<float>(uBox.x), static_cast<float>(uBox.y)));
	bb.push_back(cv::Point2f(static_cast<float>(uBox.x + uBox.width), static_cast<float>(uBox.y)));
	bb.push_back(cv::Point2f(static_cast<float>(uBox.x + uBox.width), static_cast<float>(uBox.y + uBox.height)));
	bb.push_back(cv::Point2f(static_cast<float>(uBox.x), static_cast<float>(uBox.y + uBox.height)));

	std::vector<cv::Point2f> quad_scaled_bb;
	quad_scaled_bb.push_back(cv::Point2f(1, 1));
	quad_scaled_bb.push_back(cv::Point2f(quad_img.cols, 1));
	quad_scaled_bb.push_back(cv::Point2f(quad_img.cols, quad_img.rows));
	quad_scaled_bb.push_back(cv::Point2f(1, quad_img.rows));
	
	// 1. Process image model
	tracker.setFirstFrame(tmp_img_model, bb);

	// 2. Process image frame
	int max_frames = 709;
	image_model.copyTo(normalView_pair.img_pair.first);

	for (int i = 2; i < max_frames; i++, fps.tick())
	{
		std::string filename = cv_makeFilename(".\\sampleA\\result_", i, PNG);
		frontal_gen.akaze2_frontal_warping(normalView_pair.img_pair, frontalView_pair.img_pair,		/* camera frames */
											normalView_pair.kp_pair, normalView_pair.desc_pair,		/* keypoint and descriptor */
											toFrontal_H.first);										/* fronto-parallel tform */

		if (!frontalView_pair.img_pair.second.empty())
		{
			// Get image corners of the warped image
			cv::Mat pts_H = create_homography_map(normalView_pair.img_pair.first, toFrontal_H.first);
			cv::Mat pts_Hinv = pts_H.inv();
			std::vector<cv::Point2f> bb = transform_via_homography(frame_corner, pts_H);
			
			// 2a Perform tracking-by-detection
			tracker_result result = tracker.process(frontalView_pair.img_pair.first, bb, tracker_options::FAST);
			
			// 2b Draw matches result
			if (result.inlier_matches.size())
			{
				// Draw matching result, back-project bounding box
				cv::Mat matchingMat, bbMat;
				normalView_pair.img_pair.first.copyTo(bbMat);
				cv::drawMatches(tmp_img_model, result.inliers1, frontalView_pair.img_pair.first, result.inliers2, result.inlier_matches, matchingMat, cv::Scalar(255, 0, 0), cv::Scalar(255, 0, 0));
				std::vector<cv::Point2f> tmp_boundingBox = transform_via_homography(result.boundingBox, pts_Hinv);
				std::vector<cv::Point2f> bbox = filter.correct(tmp_boundingBox);

				cv::Mat warped_quad_img;
				cv::Mat T = getPerspectiveTransform(quad_scaled_bb, bbox);
				cv::warpPerspective(quad_img, warped_quad_img, T, bbMat.size());
				overlayImage(&bbMat, &warped_quad_img);
				
				drawBoundingBox(bbMat, bbox, cv::Scalar(0, 255, 0));
				//drawBoundingBox(bbMat, tmp_boundingBox);
				
				// Show results
				cv::imshow("warped object", warped_quad_img);
				//cv::imshow("fronto-tracking", matchingMat);
				cv::imshow("AR result", bbMat);
				
				// Memory release
				matchingMat.release();
				bbMat.release();
			}
			else
			{
				std::cout << "no matches are found" << '\n';
			}
		}

		// Memory release
		normalView_pair.swap();
		frontalView_pair.swap();
		toFrontal_H.first.copyTo(toFrontal_H.second);
		normalView_pair.img_pair.first = cv::imread(filename);
		if (normalView_pair.img_pair.first.empty())
		{
			std::cerr << "Cannot open image frame, exiting the progam" << std::endl;
			return 2;
		}

		// ESC to exit the program
		if (cv::waitKey(1) == 27)
			break;
	}
	return 0;
}

void overlayImage(cv::Mat* src, cv::Mat* overlay, const cv::Point location, double opacity)
{
	bool set_opacity = false;
	if (opacity <= 0.0f | opacity > 1.0f)
		set_opacity = true;

	for (int y = max(location.y, 0); y < src->rows; ++y)
	{
		int fY = y - location.y;

		if (fY >= overlay->rows)
			break;

		for (int x = max(location.x, 0); x < src->cols; ++x)
		{
			int fX = x - location.x;

			if (fX >= overlay->cols)
				break;

			if (set_opacity)
				opacity = ((double)overlay->data[fY * overlay->step + fX * overlay->channels() + 3]) / 255;

			for (int c = 0; opacity > 0 && c < src->channels(); ++c)
			{
				unsigned char overlayPx = overlay->data[fY * overlay->step + fX * overlay->channels() + c];
				unsigned char srcPx = src->data[y * src->step + x * src->channels() + c];
				src->data[y * src->step + src->channels() * x + c] = srcPx *(1. - opacity) + overlayPx * opacity;
			}
		}
	}
}